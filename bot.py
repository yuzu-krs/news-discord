"""
IT News Discord Bot
- Zenn ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹
- ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ IT ãƒ›ãƒƒãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼
- CodeZine æ–°ç€è¨˜äº‹
ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å®šæœŸå–å¾—ã—ã€Discordãƒãƒ£ãƒ³ãƒãƒ«ã«è‡ªå‹•æŠ•ç¨¿ã™ã‚‹ã€‚
"""

import asyncio
import hashlib
import json
import os
import time
from datetime import datetime, timezone, timedelta, time
from pathlib import Path

import aiohttp
import discord
import feedparser
from discord.ext import commands, tasks
from dotenv import load_dotenv

# â”€â”€ è¨­å®šèª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

TOKEN = os.getenv("DISCORD_TOKEN")
CHANNEL_ID = int(os.getenv("DISCORD_CHANNEL_ID", "0"))
CHECK_INTERVAL_MINUTES = int(os.getenv("CHECK_INTERVAL_MINUTES", "30"))

# RSSãƒ•ã‚£ãƒ¼ãƒ‰å®šç¾©
RSS_FEEDS = [
    # â”€â”€ é–‹ç™ºè€…å‘ã‘ãƒ¡ãƒ‡ã‚£ã‚¢ â”€â”€
    {
        "name": "Zenn ãƒˆãƒ¬ãƒ³ãƒ‰",
        "url": "https://zenn.dev/feed",
        "color": 0x3EA8FF,   # Zenn ãƒ–ãƒ«ãƒ¼
        "icon": "https://zenn.dev/images/logo-transparent.png",
    },
    {
        "name": "Qiita ãƒˆãƒ¬ãƒ³ãƒ‰",
        "url": "https://qiita.com/popular-items/feed",
        "color": 0x55C500,   # Qiita ã‚°ãƒªãƒ¼ãƒ³
        "icon": "https://cdn.qiita.com/assets/favicons/public/icon-plain.ico",
    },
    {
        "name": "ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ IT",
        "url": "https://b.hatena.ne.jp/hotentry/it.rss",
        "color": 0x00A4DE,   # ã¯ã¦ãªãƒ–ãƒ«ãƒ¼
        "icon": "https://b.hatena.ne.jp/favicon.ico",
    },
    {
        "name": "CodeZine æ–°ç€è¨˜äº‹",
        "url": "https://codezine.jp/rss/new/20/index.xml",
        "color": 0x0A7E07,   # CodeZine ã‚°ãƒªãƒ¼ãƒ³
        "icon": "https://codezine.jp/lib/img/common/cz_logo_black.svg",
    },
    # â”€â”€ ãƒ†ãƒƒã‚¯ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹ â”€â”€
    {
        "name": "Publickey",
        "url": "https://www.publickey1.jp/atom.xml",
        "color": 0xDD4814,   # Publickey ã‚ªãƒ¬ãƒ³ã‚¸
        "icon": "https://www.publickey1.jp/favicon.ico",
    },
    {
        "name": "ITmedia NEWS",
        "url": "https://rss.itmedia.co.jp/rss/2.0/news_bursts.xml",
        "color": 0xEB0000,   # ITmedia ãƒ¬ãƒƒãƒ‰
        "icon": "https://www.itmedia.co.jp/favicon.ico",
    },
    {
        "name": "@IT",
        "url": "https://rss.itmedia.co.jp/rss/2.0/ait.xml",
        "color": 0x0078D4,   # @IT ãƒ–ãƒ«ãƒ¼
        "icon": "https://atmarkit.itmedia.co.jp/favicon.ico",
    },
    {
        "name": "Gihyo.jp",
        "url": "https://gihyo.jp/feed/rss2",
        "color": 0x2B2B2B,   # Gihyo ãƒ€ãƒ¼ã‚¯
        "icon": "https://gihyo.jp/favicon.ico",
    },
    {
        "name": "GIGAZINE",
        "url": "https://gigazine.net/news/rss_2.0/",
        "color": 0x333333,   # GIGAZINE ãƒ–ãƒ©ãƒƒã‚¯
        "icon": "https://gigazine.net/favicon.ico",
        # dc:subject ã§ITç³»ã‚«ãƒ†ã‚´ãƒªã®ã¿ã«çµã‚‹
        "categories": {"AI", "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢", "ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹", "ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒª"},
    },
]

# æ—¢èª­ç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ«
SEEN_FILE = Path(__file__).parent / "seen_articles.json"


# â”€â”€ æ—¢èª­ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_seen() -> dict[str, list[str]]:
    """æ—¢ã«æŠ•ç¨¿æ¸ˆã¿ã®è¨˜äº‹IDã‚’èª­ã¿è¾¼ã‚€"""
    if SEEN_FILE.exists():
        try:
            return json.loads(SEEN_FILE.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            pass
    return {}


def save_seen(seen: dict[str, list[str]]) -> None:
    """æŠ•ç¨¿æ¸ˆã¿ã®è¨˜äº‹IDã‚’ä¿å­˜ã™ã‚‹"""
    SEEN_FILE.write_text(json.dumps(seen, ensure_ascii=False, indent=2), encoding="utf-8")


def article_id(entry: dict) -> str:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰ä¸€æ„IDã‚’ç”Ÿæˆã™ã‚‹"""
    raw = entry.get("id") or entry.get("link") or entry.get("title", "")
    return hashlib.sha256(raw.encode()).hexdigest()[:16]


# â”€â”€ ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def fetch_feed(session: aiohttp.ClientSession, url: str) -> feedparser.FeedParserDict:
    """éåŒæœŸã§RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as resp:
            text = await resp.text()
            return feedparser.parse(text)
    except Exception as e:
        print(f"[ERROR] ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•—: {url} - {e}")
        return feedparser.FeedParserDict()


# â”€â”€ Embedä½œæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JST = timezone(timedelta(hours=9))


def make_embed(entry: dict, feed_meta: dict) -> discord.Embed:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰Discord Embedã‚’ä½œæˆã™ã‚‹"""
    title = entry.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")
    link = entry.get("link", "")
    summary = entry.get("summary", entry.get("description", ""))

    # HTMLã‚¿ã‚°ã‚’ç°¡æ˜“é™¤å»
    import re
    summary = re.sub(r"<[^>]+>", "", summary)
    if len(summary) > 200:
        summary = summary[:200] + "â€¦"

    embed = discord.Embed(
        title=title,
        url=link,
        description=summary if summary else None,
        color=feed_meta["color"],
    )

    # å…¬é–‹æ—¥æ™‚
    published = entry.get("published_parsed") or entry.get("updated_parsed")
    if published:
        try:
            dt = datetime(*published[:6], tzinfo=timezone.utc)
            embed.timestamp = dt
        except Exception:
            pass

    # è‘—è€…
    author = entry.get("author")
    if author:
        embed.set_author(name=author)

    # ãƒ•ãƒƒã‚¿ãƒ¼: ãƒ•ã‚£ãƒ¼ãƒ‰å
    embed.set_footer(text=feed_meta["name"])

    # ã‚µãƒ ãƒã‚¤ãƒ« (ã¯ã¦ãƒ–ã«ã¯enclosureãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹)
    if "media_thumbnail" in entry and entry["media_thumbnail"]:
        embed.set_thumbnail(url=entry["media_thumbnail"][0].get("url", ""))
    elif "enclosures" in entry and entry["enclosures"]:
        enc = entry["enclosures"][0]
        if enc.get("type", "").startswith("image"):
            embed.set_thumbnail(url=enc.get("href", ""))

    return embed


# â”€â”€ æœã®ãƒ•ã‚£ãƒ¼ãƒ‰å®šç¾© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MORNING_FEED_NAMES = {"Qiita ãƒˆãƒ¬ãƒ³ãƒ‰", "Zenn ãƒˆãƒ¬ãƒ³ãƒ‰", "GIGAZINE"}
MORNING_FEEDS = [f for f in RSS_FEEDS if f["name"] in MORNING_FEED_NAMES]
MORNING_TIME = time(hour=7, minute=0, tzinfo=JST)   # æ¯æœ 7:00 JST
WEEKLY_TIME  = time(hour=9, minute=0, tzinfo=JST)   # æ¯é€±æ—¥æ›œ 9:00 JST

# â”€â”€ ãƒ›ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HOT_KEYWORDS = [
    "AI", "ChatGPT", "GPT", "LLM", "ç”ŸæˆAI", "Claude", "Gemini", "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
    "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "è„†å¼±æ€§", "ã‚¼ãƒ­ãƒ‡ã‚¤", "ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒ",
    "TypeScript", "Python", "Rust", "React", "Next.js", "Vue", "Go",
    "ã‚¯ãƒ©ã‚¦ãƒ‰", "AWS", "Azure", "GCP", "Kubernetes", "Docker",
    "GitHub", "OSS", "ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹",
    "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—", "è³‡é‡‘èª¿é”", "å‰²æ‚¹",
]


def score_entry(entry: dict, feed_meta: dict) -> int:
    """ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒ›ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° + ãƒ•ã‚£ãƒ¼ãƒ‰ãƒœãƒ¼ãƒŠã‚¹ã§ã‚¹ã‚³ã‚¢ã‚’è¿”ã™"""
    title = entry.get("title", "")
    score = sum(1 for kw in HOT_KEYWORDS if kw.lower() in title.lower())
    # Qiita/Zennã¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ç‰¹åŒ–ãªã®ã§ãƒœãƒ¼ãƒŠã‚¹
    if feed_meta["name"] in ("Qiita ãƒˆãƒ¬ãƒ³ãƒ‰", "Zenn ãƒˆãƒ¬ãƒ³ãƒ‰"):
        score += 1
    return score


def pick_spotlight(
    results: list[tuple[dict, list[tuple[str, dict]]]],
) -> tuple[dict, dict] | None:
    """åé›†è¨˜äº‹ã®ä¸­ã‹ã‚‰æœ€é«˜ã‚¹ã‚³ã‚¢ã®1æœ¬ã‚’è¿”ã™"""
    best: tuple[int, dict, dict] | None = None
    for feed_meta, entries in results:
        for _, entry in entries:
            s = score_entry(entry, feed_meta)
            if best is None or s > best[0]:
                best = (s, feed_meta, entry)
    if best is None:
        return None
    return best[1], best[2]  # (feed_meta, entry)


# â”€â”€ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯å…±é€šå‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _check_feeds(channel, feeds: list[dict], max_per_feed: int | None = None, shuffle: bool = False) -> int:
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§ã‚’ãƒã‚§ãƒƒã‚¯ã—æ–°ç€è¨˜äº‹ã‚’æŠ•ç¨¿ã™ã‚‹ã€‚æŠ•ç¨¿ä»¶æ•°ã‚’è¿”ã™ã€‚

    Args:
        max_per_feed: 1ãƒ•ã‚£ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§æŠ•ç¨¿ä»¶æ•°ã€‚None ã®å ´åˆã¯ç„¡åˆ¶é™ã€‚
        shuffle: True ã®å ´åˆã€æ–°ç€è¨˜äº‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã³æ›¿ãˆã¦æŠ•ç¨¿ã™ã‚‹ã€‚
    """
    seen = load_seen()
    new_count = 0

    async with aiohttp.ClientSession() as session:
        for feed_meta in feeds:
            feed_name = feed_meta["name"]
            feed = await fetch_feed(session, feed_meta["url"])

            if not feed or not feed.get("entries"):
                print(f"[WARN] {feed_name}: ã‚¨ãƒ³ãƒˆãƒªãªã—")
                continue

            if feed_name not in seen:
                seen[feed_name] = []

            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆfeedãƒ¡ã‚¿ã«"categories"ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿çµã‚Šè¾¼ã‚€ï¼‰
            allowed_categories = feed_meta.get("categories")

            # æ–°ç€ã‚’å¤ã„é †ã«ä¸¦ã¹ã¦æŠ•ç¨¿
            new_entries = []
            for entry in feed.entries:
                # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if allowed_categories:
                    subject = entry.get("tags", [])
                    # feedparserã¯dc:subjectã‚’tagsã«æ ¼ç´ã™ã‚‹ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã®å ´åˆã‚ã‚Šï¼‰
                    entry_cats = set()
                    for t in subject:
                        for part in t.get("term", "").split(","):
                            entry_cats.add(part.strip())
                    if not entry_cats & allowed_categories:
                        continue
                aid = article_id(entry)
                if aid not in seen[feed_name]:
                    new_entries.append((aid, entry))

            # ãƒ©ãƒ³ãƒ€ãƒ å–å¾—ã®å ´åˆã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            if shuffle:
                import random
                random.shuffle(new_entries)

            # åˆå›èµ·å‹•æ™‚ã¯æœ€æ–°5ä»¶ã ã‘æŠ•ç¨¿ï¼ˆå¤§é‡æŠ•ç¨¿é˜²æ­¢ï¼‰
            init_limit = max_per_feed if max_per_feed is not None else 5
            if not seen[feed_name] and len(new_entries) > init_limit:
                skipped = new_entries[:-init_limit]
                for aid, _ in skipped:
                    seen[feed_name].append(aid)
                new_entries = new_entries[-init_limit:]

            # ä»¶æ•°ä¸Šé™ã‚’é©ç”¨ï¼ˆæœ€æ–°ã®è¨˜äº‹ã‚’å„ªå…ˆï¼‰
            if max_per_feed is not None and len(new_entries) > max_per_feed:
                skipped = new_entries[:-max_per_feed]
                for aid, _ in skipped:
                    seen[feed_name].append(aid)
                new_entries = new_entries[-max_per_feed:]

            for aid, entry in new_entries:
                embed = make_embed(entry, feed_meta)
                try:
                    await channel.send(embed=embed)
                    new_count += 1
                except discord.HTTPException as e:
                    print(f"[ERROR] é€ä¿¡å¤±æ•—: {e}")
                    continue

                seen[feed_name].append(aid)
                await asyncio.sleep(1)  # ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆå¯¾ç­–

            # æ—¢èª­ãƒªã‚¹ãƒˆãŒå¤§ãããªã‚Šã™ããªã„ã‚ˆã†åˆ¶é™
            if len(seen[feed_name]) > 500:
                seen[feed_name] = seen[feed_name][-300:]

    save_seen(seen)
    return new_count


# â”€â”€ æœãƒ‹ãƒ¥ãƒ¼ã‚¹ç”¨: è¨˜äº‹ã‚’åé›†ã™ã‚‹ï¼ˆæŠ•ç¨¿ãªã—ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _collect_morning_articles(max_per_feed: int = 2) -> tuple[list[tuple], dict]:
    """æœã®ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰æ–°ç€è¨˜äº‹ã‚’åé›†ã—ã€(feed_meta, entries)ã®ãƒªã‚¹ãƒˆã¨updated seenã‚’è¿”ã™ã€‚"""
    seen = load_seen()
    results: list[tuple[dict, list[tuple[str, dict]]]] = []

    async with aiohttp.ClientSession() as session:
        for feed_meta in MORNING_FEEDS:
            feed_name = feed_meta["name"]
            feed = await fetch_feed(session, feed_meta["url"])

            if not feed or not feed.get("entries"):
                print(f"[WARN] {feed_name}: ã‚¨ãƒ³ãƒˆãƒªãªã—")
                continue

            if feed_name not in seen:
                seen[feed_name] = []

            allowed_categories = feed_meta.get("categories")

            new_entries = []
            for entry in feed.entries:
                if allowed_categories:
                    entry_cats = set()
                    for t in entry.get("tags", []):
                        for part in t.get("term", "").split(","):
                            entry_cats.add(part.strip())
                    if not entry_cats & allowed_categories:
                        continue
                aid = article_id(entry)
                if aid not in seen[feed_name]:
                    new_entries.append((aid, entry))

            # åˆå›èµ·å‹•æ™‚ã¯æœ€æ–°ä»¶ã®ã¿ï¼ˆå¤§é‡æŠ•ç¨¿é˜²æ­¢ï¼‰
            if not seen[feed_name] and len(new_entries) > max_per_feed:
                for aid, _ in new_entries[:-max_per_feed]:
                    seen[feed_name].append(aid)
                new_entries = new_entries[-max_per_feed:]

            if len(new_entries) > max_per_feed:
                for aid, _ in new_entries[:-max_per_feed]:
                    seen[feed_name].append(aid)
                new_entries = new_entries[-max_per_feed:]

            # æ—¢èª­ã«è¿½åŠ 
            for aid, _ in new_entries:
                seen[feed_name].append(aid)

            if len(seen[feed_name]) > 500:
                seen[feed_name] = seen[feed_name][-300:]

            if new_entries:
                results.append((feed_meta, new_entries))

    save_seen(seen)
    return results


# â”€â”€ æœã®å®šæ™‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ (Qiita / Zenn / GIGAZINE) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _post_morning_news(channel) -> None:
    """æœã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’1ã¤ã®Embedã«ã¾ã¨ã‚ã¦æŠ•ç¨¿ã™ã‚‹"""
    results = await _collect_morning_articles(max_per_feed=2)

    if not results:
        now = datetime.now(JST).strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{now}] ğŸŒ… æœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹: æ–°ç€ãªã—")
        return

    today = datetime.now(JST).strftime("%Y/%m/%d")

    # ä»Šæ—¥ã®æ³¨ç›®1æœ¬ã‚’descriptionã«å…¥ã‚Œã‚‹
    spotlight = pick_spotlight(results)
    spotlight_link = ""
    description = ""
    if spotlight:
        sp_feed, sp_entry = spotlight
        sp_title = sp_entry.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")
        sp_link  = sp_entry.get("link", "")
        spotlight_link = sp_link
        description = f"â­ **ä»Šæ—¥ã®æ³¨ç›®**\n[ğŸ”— {sp_title}]({sp_link})\n\nâ”â”â”â”â”â”â”â”"

    embed = discord.Embed(
        title=f"â˜€ï¸ {today} æœã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        description=description if description else None,
        color=0x5865F2,
        timestamp=datetime.now(timezone.utc),
    )

    total = 0
    for feed_meta, entries in results:
        lines = []
        for _, entry in entries:
            link = entry.get("link", "")
            # æ³¨ç›®è¨˜äº‹ã¨åŒã˜URLã¯ãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§ã‹ã‚‰é™¤å¤–ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
            if spotlight_link and link == spotlight_link:
                continue
            title = entry.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")
            lines.append(f"[ğŸ”— {title}]({link})")
            total += 1
        if not lines:
            continue
        embed.add_field(
            name=f"\n{feed_meta['name']}",
            value="\n".join(lines),
            inline=False,
        )

    embed.set_footer(text=f"è¨ˆ {total} ä»¶ | æ¯æœ 7:00 JST é…ä¿¡")

    try:
        await channel.send(embed=embed)
    except discord.HTTPException as e:
        print(f"[ERROR] æœãƒ‹ãƒ¥ãƒ¼ã‚¹é€ä¿¡å¤±æ•—: {e}")
        return

    now = datetime.now(JST).strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] ğŸŒ… æœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº† - æ–°ç€ {total} ä»¶ã‚’ã¾ã¨ã‚ã¦æŠ•ç¨¿")


@tasks.loop(time=MORNING_TIME)
async def morning_news():
    """æ¯æœ 7:00 JST ã« Qiitaãƒ»Zennãƒ»GIGAZINE ã®æœ€æ–°è¨˜äº‹ã‚’æŠ•ç¨¿ã™ã‚‹"""
    channel = bot.get_channel(CHANNEL_ID)
    if channel is None:
        print(f"[ERROR] ãƒãƒ£ãƒ³ãƒãƒ« {CHANNEL_ID} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    await _post_morning_news(channel)


@morning_news.before_loop
async def before_morning_news():
    await bot.wait_until_ready()


@morning_news.error
async def morning_news_error(error):
    now = datetime.now(JST).strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] âŒ morning_news ã‚¨ãƒ©ãƒ¼: {error}")
    import traceback
    traceback.print_exc()
    # ã‚¿ã‚¹ã‚¯ãŒåœæ­¢ã—ãŸå ´åˆã¯å†èµ·å‹•
    if not morning_news.is_running():
        morning_news.restart()


# â”€â”€ Bot æœ¬ä½“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)


@bot.event
async def on_ready():
    print(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†: {bot.user} (ID: {bot.user.id})")
    print(f"ğŸ“¡ ãƒãƒ£ãƒ³ãƒãƒ«ID: {CHANNEL_ID}")
    print(f"ğŸŒ… æœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹: æ¯æ—¥ {MORNING_TIME.strftime('%H:%M')} JST")

    # èµ·å‹•æ™‚ã«æœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿
    channel = bot.get_channel(CHANNEL_ID)
    if channel:
        print("ğŸ“° èµ·å‹•æ™‚ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿ä¸­...")
        await _post_morning_news(channel)
    else:
        print(f"[ERROR] ãƒãƒ£ãƒ³ãƒãƒ« {CHANNEL_ID} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    if not morning_news.is_running():
        morning_news.start()
        print("âœ… morning_news ã‚¿ã‚¹ã‚¯é–‹å§‹")
    if not weekly_ranking.is_running():
        weekly_ranking.start()
        print("âœ… weekly_ranking ã‚¿ã‚¹ã‚¯é–‹å§‹")


# â”€â”€ é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚° (æ¯é€±æ—¥æ›œ 9:00 JST) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _post_weekly_ranking(channel) -> None:
    """ã¯ã¦ãƒŠBM ITãƒ›ãƒƒãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ TOP5 ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã§æŠ•ç¨¿ã™ã‚‹"""
    async with aiohttp.ClientSession() as session:
        feed = await fetch_feed(session, "https://b.hatena.ne.jp/hotentry/it.rss")

    if not feed or not feed.get("entries"):
        print("[WARN] é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚°: ã‚¨ãƒ³ãƒˆãƒªãªã—")
        return

    entries = feed.entries[:5]
    week_start = (datetime.now(JST) - timedelta(days=6)).strftime("%m/%d")
    week_end   = datetime.now(JST).strftime("%m/%d")

    embed = discord.Embed(
        title=f"ğŸ† ä»Šé€±ã®ITãƒ‹ãƒ¥ãƒ¼ã‚¹ ãƒ©ãƒ³ã‚­ãƒ³ã‚° TOP5",
        description=f"{week_start} ã€œ {week_end}ã€€|ã€€ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ ITãƒ›ãƒƒãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚ˆã‚Š",
        color=0x00A4DE,
        timestamp=datetime.now(timezone.utc),
    )

    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]
    for i, entry in enumerate(entries):
        title  = entry.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")
        link   = entry.get("link", "")
        bcount = getattr(entry, "hatena_bookmarkcount", "") or ""
        count_str = f"ã€€ğŸ”– {bcount}ä»¶" if bcount else ""
        embed.add_field(
            name=f"{medals[i]}ã€€{title}",
            value=f"[{link}]({link}){count_str}",
            inline=False,
        )

    embed.set_footer(text="æ¯é€±æ—¥æ›œ 9:00 JST é…ä¿¡")
    try:
        await channel.send(embed=embed)
        now = datetime.now(JST).strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{now}] ğŸ† é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚°æŠ•ç¨¿å®Œäº†")
    except discord.HTTPException as e:
        print(f"[ERROR] é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚°é€ä¿¡å¤±æ•—: {e}")


@tasks.loop(time=WEEKLY_TIME)
async def weekly_ranking():
    """æ¯é€±æ—¥æ›œ 9:00 JST ã«é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æŠ•ç¨¿ã™ã‚‹"""
    if datetime.now(JST).weekday() != 6:  # 6 = æ—¥æ›œ
        return
    channel = bot.get_channel(CHANNEL_ID)
    if channel is None:
        return
    await _post_weekly_ranking(channel)


@weekly_ranking.before_loop
async def before_weekly_ranking():
    await bot.wait_until_ready()


# â”€â”€ ã‚³ãƒãƒ³ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bot.command(name="ranking")
async def cmd_ranking(ctx):
    """æ‰‹å‹•ã§é€±åˆŠãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤ºã™ã‚‹"""
    await ctx.send("ğŸ“¥ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ä¸­â€¦")
    await _post_weekly_ranking(ctx.channel)


@bot.command(name="news")
async def cmd_news(ctx):
    """æ‰‹å‹•ã§æœ€æ–°è¨˜äº‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å–å¾—ã—ã¦æŠ•ç¨¿ã™ã‚‹"""
    await ctx.send("ğŸ”„ ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ä¸­â€¦")
    channel = ctx.channel
    new_count = await _check_feeds(channel, MORNING_FEEDS, max_per_feed=5, shuffle=True)
    if new_count == 0:
        await ctx.send("âš ï¸ æ–°ç€è¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆæ—¢èª­æ¸ˆã¿ï¼‰")
    else:
        await ctx.send(f"âœ… {new_count} ä»¶ã®è¨˜äº‹ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼")


@bot.command(name="status")
async def cmd_status(ctx):
    """Botã®çŠ¶æ…‹ã‚’è¡¨ç¤ºã™ã‚‹"""
    seen = load_seen()
    embed = discord.Embed(
        title="ğŸ“Š Bot ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
        color=0x5865F2,
    )
    for feed_meta in RSS_FEEDS:
        name = feed_meta["name"]
        count = len(seen.get(name, []))
        embed.add_field(name=name, value=f"æ—¢èª­: {count} ä»¶", inline=True)

    embed.add_field(
        name="ãƒã‚§ãƒƒã‚¯é–“éš”",
        value=f"{CHECK_INTERVAL_MINUTES} åˆ†",
        inline=False,
    )
    embed.set_footer(text=f"morning_news ã‚¿ã‚¹ã‚¯ç¨¼åƒä¸­={'âœ…' if morning_news.is_running() else 'âŒ'}")
    await ctx.send(embed=embed)


@bot.command(name="reset")
@commands.is_owner()
async def cmd_reset(ctx):
    """æ—¢èª­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ï¼ˆBotæ‰€æœ‰è€…ã®ã¿ï¼‰"""
    if SEEN_FILE.exists():
        SEEN_FILE.unlink()
    await ctx.send("ğŸ—‘ æ—¢èª­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")


# â”€â”€ èµ·å‹• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    if not TOKEN:
        print("âŒ DISCORD_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        exit(1)
    if CHANNEL_ID == 0:
        print("âŒ DISCORD_CHANNEL_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        exit(1)

    bot.run(TOKEN)
